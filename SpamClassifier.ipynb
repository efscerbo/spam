{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style = \"whitegrid\", \n",
    "        color_codes = True,\n",
    "        font_scale = 1.5)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "emails = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8348 rows in the dataset and 4 columns.\n"
     ]
    }
   ],
   "source": [
    "# Check shape\n",
    "print(f'There are {emails.shape[0]} rows in the '\n",
    "      f'dataset and {emails.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicates in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "unique_PIDs = len(emails['id'].unique())\n",
    "total_PIDs = emails.shape[0]\n",
    "number_of_dupes = total_PIDs - unique_PIDs\n",
    "print(f'There are {number_of_dupes} duplicates in the dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split, seeded for replication\n",
    "train, test = train_test_split(emails, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject    6\n",
       "spam       0\n",
       "email      0\n",
       "id         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "train.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ham     74.63064\n",
       "Spam    25.36936\n",
       "Name: spam, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class imbalance?\n",
    "train['spam'].replace({0: 'Ham', 1: 'Spam'}).value_counts() * 100 / len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some emails have NaNs for their subjects\n",
    "def handle_missing_data(data):\n",
    "    data = data.fillna('')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frac_upper(string):\n",
    "    \"\"\"Computes the fraction of alphabetical characters\n",
    "    in STRING that are uppercase. If no alphabetical\n",
    "    characters, returns 0.\"\"\"\n",
    "    num_upper = len(re.findall(r'[A-Z]', string))\n",
    "    num_letters = len(re.findall(r'[a-zA-Z]', string))\n",
    "    if num_letters == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return num_upper / num_letters\n",
    "    \n",
    "def number_of(regex):\n",
    "    \"\"\"Returns a lambda that when applied to a string\n",
    "    will count the number of occurences of REGEX in the\n",
    "    string (for use in making new features below).\"\"\"\n",
    "    return lambda string: len(re.findall(regex, string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_features(data):\n",
    "    # Combine subject and email columns\n",
    "    data['combined'] = data['subject'] + ' ' + data['email']\n",
    "\n",
    "    # Make everything in 'combined' lowercase and remove punctuation\n",
    "    data['no_punc'] = (\n",
    "        data['combined']\n",
    "        .str.lower()\n",
    "        .str.replace(pat=r'[^\\w\\s]', repl=' ')\n",
    "    )\n",
    "    \n",
    "    # Count number of characters, words, new line characters,\n",
    "    # etc. Take logs of these. Also compute fraction of\n",
    "    # uppercase letters in email\n",
    "    data['log_chars'] = np.log1p(data['combined'].apply(len))\n",
    "    data['log_words'] = np.log1p(data['no_punc'].apply(lambda string: len(string.split())))\n",
    "    data['log_new_lines'] = np.log1p(data['combined'].apply(number_of(r'[\\n]')))\n",
    "    data['log_angle_brackets'] = np.log1p(data['combined'].apply(number_of(r'[<>]')))\n",
    "    data['log_exclamations'] = np.log1p(data['combined'].apply(number_of(r'[!]')))\n",
    "    data['log_punctuation'] = np.log1p(data['combined'].apply(number_of(r'[\\n$%<>!?]')))\n",
    "    data['frac_upper'] = data['combined'].apply(frac_upper)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following function runs only on 'train' so as to\n",
    "# guarantee that, when we run our data through the pipeline,\n",
    "# the same words are used for both 'train' and 'test'.\n",
    "def spam_ham_words(min_emails, num_spam, num_ham):\n",
    "    # Combine subject and email columns\n",
    "    train['combined'] = train['subject'] + ' ' + train['email']\n",
    "    \n",
    "    # Make everything in 'combined' lowercase and remove punctuation\n",
    "    train['no_punc'] = (\n",
    "        train['combined']\n",
    "        .str.lower()\n",
    "        .str.replace(pat=r'[^\\w\\s]', repl=' ')\n",
    "    )\n",
    "    \n",
    "    # Put email text into \"tidy format\", i.e., each word of each\n",
    "    # email gets put into its own row, indexed by id of email\n",
    "    tidy_format = (\n",
    "        train['no_punc']\n",
    "        .str.split(expand=True)\n",
    "        .stack()\n",
    "        .reset_index(level=1)\n",
    "        .rename(columns={'level_1': 'num', 0: 'word'})\n",
    "        # The following lines drop repeated words in same email\n",
    "        # Not sure if should keep these\n",
    "        .drop('num', axis=1)\n",
    "        .reset_index()\n",
    "        .drop_duplicates()\n",
    "        .set_index('index')\n",
    "    )\n",
    "    \n",
    "    # Find which words are most indicative of a spam email\n",
    "    # versus a ham email. Limit to words appearing in at\n",
    "    # least 'min_emails' emails\n",
    "    words = (\n",
    "        tidy_format\n",
    "        .groupby('word')\n",
    "        .filter(lambda x: x.index.nunique() >= min_emails)\n",
    "        .merge(train[['spam']], how=\"left\", left_index=True, right_index=True)\n",
    "        .groupby('word')[['spam']]\n",
    "        .mean()\n",
    "        .sort_values('spam', ascending=False)\n",
    "    )\n",
    "    \n",
    "    spam_words = words.index[:num_spam].tolist()\n",
    "    ham_words = words.index[-num_ham:].tolist()\n",
    "    \n",
    "    words = spam_words + ham_words\n",
    "    \n",
    "    return words\n",
    "\n",
    "def words_in_texts(words, texts):\n",
    "    \"\"\"Returns a dataframe the (i, j)^th entry of which is 1 \n",
    "    if the i^th element of TEXTS contains the j^th element of\n",
    "    WORDS as a substring and is 0 otherwise.\"\"\"\n",
    "    indicator_array = np.array([texts.str.contains(word).astype(int) for word in words]).T\n",
    "    df = pd.DataFrame(indicator_array, columns=words)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_words_cols(data, words):\n",
    "    \"\"\"For each word in WORDS, appends a binary feature \n",
    "    indicating whether that word appears in a given email.\"\"\"\n",
    "    # Must reset index on 'data' for use in concat\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    words_in_texts_df = words_in_texts(words, data['no_punc'])\n",
    "    data = pd.concat([data, words_in_texts_df], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneeded columns\n",
    "def drop_cols(data, cols):\n",
    "    data = data.drop(cols, axis=1)\n",
    "    return data\n",
    "\n",
    "cols_to_drop = ['id', 'subject', 'email', 'combined', 'no_punc']\n",
    "#cols_to_drop = ['id', 'subject', 'email', 'combined', 'no_punc', 'log_angle_brackets', 'log_exclamations']\n",
    "\n",
    "# The graphs for 'log_angle_brackets' and 'log_exclamations'\n",
    "# are strange. Not clear whether we should include these\n",
    "# features. We'll try running the model with them and\n",
    "# try it again without them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/efscerbo/anaconda3/envs/data100/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/efscerbo/anaconda3/envs/data100/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Put this in the for loop over all hyperparams\n",
    "min_emails, num_spam, num_ham = (600, 90, 60)\n",
    "\n",
    "words = spam_ham_words(min_emails, num_spam, num_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process_pipeline(data):\n",
    "    data = (\n",
    "        data\n",
    "        .pipe(handle_missing_data)\n",
    "        .pipe(make_new_features)\n",
    "        .pipe(append_words_cols, words)\n",
    "        .pipe(drop_cols, cols_to_drop)\n",
    "    )\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataframes before modeling. Rename 'spam' as\n",
    "# 'Spam' bc one of the words found by 'spam_ham_words'\n",
    "# is 'spam'\n",
    "processed_train = data_process_pipeline(train.copy().rename(columns={'spam': 'Spam'}))\n",
    "processed_test = data_process_pipeline(test.copy().rename(columns={'spam': 'Spam'}))\n",
    "\n",
    "X_train = processed_train.drop('Spam', axis=1)\n",
    "y_train = processed_train['Spam']\n",
    "X_test = processed_test.drop('Spam', axis=1)\n",
    "y_test = processed_test['Spam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider using LogisticRegressionCV\n",
    "#### Also, hyperparams to tweak: 'min_emails', 'num_spam', and 'num_ham' in 'spam_ham_words', as well as classification threshold in LogisticRegression model object. Also consider dropping the 'log_angle_brackets' and 'log_exclamations' cols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9801677093038733\n",
      "Test Accuracy:  0.9640718562874252\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "training_accuracy = model.score(X_train, y_train)\n",
    "test_accuracy = model.score(X_test, y_test)\n",
    "print('Training Accuracy: ', training_accuracy)\n",
    "print('Test Accuracy: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4: 0.9652694610778443\n",
      "0.40714285714285714: 0.9640718562874252\n",
      "0.4142857142857143: 0.9640718562874252\n",
      "0.42142857142857143: 0.9640718562874252\n",
      "0.4285714285714286: 0.9640718562874252\n",
      "0.4357142857142857: 0.9652694610778443\n",
      "0.4428571428571429: 0.9652694610778443\n",
      "0.45: 0.9676646706586827\n",
      "0.4571428571428572: 0.9676646706586827\n",
      "0.4642857142857143: 0.9664670658682635\n",
      "0.4714285714285714: 0.9676646706586827\n",
      "0.4785714285714286: 0.9676646706586827\n",
      "0.48571428571428577: 0.9652694610778443\n",
      "0.4928571428571429: 0.9652694610778443\n",
      "0.5: 0.9640718562874252\n",
      "0.5071428571428571: 0.9640718562874252\n",
      "0.5142857142857143: 0.9640718562874252\n",
      "0.5214285714285715: 0.9640718562874252\n",
      "0.5285714285714286: 0.9640718562874252\n",
      "0.5357142857142857: 0.9652694610778443\n",
      "0.5428571428571429: 0.9664670658682635\n",
      "0.55: 0.9664670658682635\n",
      "0.5571428571428572: 0.9664670658682635\n",
      "0.5642857142857143: 0.9664670658682635\n",
      "0.5714285714285714: 0.9652694610778443\n",
      "0.5785714285714286: 0.9640718562874252\n",
      "0.5857142857142857: 0.962874251497006\n",
      "0.5928571428571429: 0.9640718562874252\n",
      "0.6: 0.9640718562874252\n",
      "0.6071428571428572: 0.962874251497006\n",
      "0.6142857142857143: 0.9616766467065868\n",
      "0.6214285714285714: 0.9616766467065868\n",
      "0.6285714285714286: 0.9616766467065868\n",
      "0.6357142857142857: 0.9616766467065868\n",
      "0.6428571428571429: 0.9616766467065868\n",
      "0.65: 0.9616766467065868\n",
      "0.6571428571428571: 0.9592814371257485\n",
      "0.6642857142857144: 0.9592814371257485\n",
      "0.6714285714285715: 0.9592814371257485\n",
      "0.6785714285714286: 0.9592814371257485\n",
      "0.6857142857142857: 0.9592814371257485\n",
      "0.6928571428571428: 0.9592814371257485\n",
      "0.7: 0.9592814371257485\n",
      "0.7071428571428571: 0.9592814371257485\n",
      "0.7142857142857143: 0.9592814371257485\n",
      "0.7214285714285714: 0.9580838323353293\n",
      "0.7285714285714286: 0.9580838323353293\n",
      "0.7357142857142858: 0.9580838323353293\n",
      "0.7428571428571429: 0.9580838323353293\n",
      "0.75: 0.9580838323353293\n"
     ]
    }
   ],
   "source": [
    "# Trying different classification thresholds\n",
    "for C in np.linspace(0.4, 0.75):\n",
    "    y_pred_diff_thresh = 1*(model.predict_proba(X_test)[:, 1] > C)\n",
    "    print(str(C) + ':', sum(y_pred_diff_thresh == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "min_emails_range = range(600, 1201, 100)\n",
    "num_spam_range = range(30, 101, 15)\n",
    "num_ham_range = range(30, 101, 15)\n",
    "\n",
    "training_scores = {}\n",
    "test_scores = {}\n",
    "\n",
    "for triple in itertools.product(min_emails_range, num_spam_range, num_ham_range):\n",
    "    print(triple)\n",
    "    \n",
    "    min_emails, num_spam, num_ham = triple\n",
    "    \n",
    "    words = spam_ham_words(min_emails, num_spam, num_ham)\n",
    "    \n",
    "    processed_train = data_process_pipeline(train.copy().rename(columns={'spam': 'Spam'}))\n",
    "    processed_test = data_process_pipeline(test.copy().rename(columns={'spam': 'Spam'}))\n",
    "    \n",
    "    X_train = processed_train.drop('Spam', axis=1)\n",
    "    y_train = processed_train['Spam']\n",
    "    X_test = processed_test.drop('Spam', axis=1)\n",
    "    y_test = processed_test['Spam']\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    training_accuracy = model.score(X_train, y_train)\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "    \n",
    "    training_scores[triple] = training_accuracy\n",
    "    test_scores[triple] = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(test_scores, key=test_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(training_scores, key=training_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a29301f60>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.98       601\n",
      "          1       0.96      0.91      0.93       234\n",
      "\n",
      "avg / total       0.96      0.96      0.96       835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict_proba(X_train)[:, 1]\n",
    "prec, recall, _ = precision_recall_curve(y_train, y_predict)\n",
    "plt.plot(recall, prec)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "evaluation = pd.read_csv('data/eval.csv')\n",
    "evaluation_predictions = model.predict(data_process_pipeline(evaluation.copy()))\n",
    "\n",
    "# Construct and save the submission:\n",
    "submission_df = pd.DataFrame({\n",
    "    \"Id\": evaluation['id'], \n",
    "    \"Class\": evaluation_predictions,\n",
    "}, columns=['Id', 'Class'])\n",
    "timestamp = datetime.isoformat(datetime.now()).split(\".\")[0]\n",
    "submission_df.to_csv(\"submission_{}.csv\".format(timestamp), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
