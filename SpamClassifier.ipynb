{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style = \"whitegrid\", \n",
    "        color_codes = True,\n",
    "        font_scale = 1.5)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "emails = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails.loc[:3999, :].to_csv('train_1.csv', index=False)\n",
    "emails.loc[4000:, :].to_csv('train_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subject</th>\n",
       "      <th>email</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: A&amp;L Daily to be auctioned in bankrupt...</td>\n",
       "      <td>URL: http://boingboing.net/#85534171\\n Date: N...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: Wired: \"Stronger ties between ISPs an...</td>\n",
       "      <td>URL: http://scriptingnews.userland.com/backiss...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Subject: It's just too small                  ...</td>\n",
       "      <td>&lt;HTML&gt;\\n &lt;HEAD&gt;\\n &lt;/HEAD&gt;\\n &lt;BODY&gt;\\n &lt;FONT SIZ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Subject: liberal defnitions\\n</td>\n",
       "      <td>Depends on how much over spending vs. how much...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Subject: RE: [ILUG] Newbie seeks advice - Suse...</td>\n",
       "      <td>hehe sorry but if you hit caps lock twice the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            subject  \\\n",
       "0   0  Subject: A&L Daily to be auctioned in bankrupt...   \n",
       "1   1  Subject: Wired: \"Stronger ties between ISPs an...   \n",
       "2   2  Subject: It's just too small                  ...   \n",
       "3   3                      Subject: liberal defnitions\\n   \n",
       "4   4  Subject: RE: [ILUG] Newbie seeks advice - Suse...   \n",
       "\n",
       "                                               email  spam  \n",
       "0  URL: http://boingboing.net/#85534171\\n Date: N...     0  \n",
       "1  URL: http://scriptingnews.userland.com/backiss...     0  \n",
       "2  <HTML>\\n <HEAD>\\n </HEAD>\\n <BODY>\\n <FONT SIZ...     1  \n",
       "3  Depends on how much over spending vs. how much...     0  \n",
       "4  hehe sorry but if you hit caps lock twice the ...     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_1 = pd.read_csv('data/train_1.csv')\n",
    "emails_2 = pd.read_csv('data/train_2.csv')\n",
    "emails = pd.concat([emails_1, emails_2], ignore_index=True)\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8348 rows in the dataset and 4 columns.\n"
     ]
    }
   ],
   "source": [
    "# Check shape\n",
    "print(f'There are {emails.shape[0]} rows in the '\n",
    "      f'dataset and {emails.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicates in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "unique_PIDs = len(emails['id'].unique())\n",
    "total_PIDs = emails.shape[0]\n",
    "number_of_dupes = total_PIDs - unique_PIDs\n",
    "print(f'There are {number_of_dupes} duplicates in the dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split, seeded for replication\n",
    "train, test = train_test_split(emails, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject    6\n",
       "spam       0\n",
       "email      0\n",
       "id         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "train.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ham     74.63064\n",
       "Spam    25.36936\n",
       "Name: spam, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class imbalance?\n",
    "train['spam'].replace({0: 'Ham', 1: 'Spam'}).value_counts() * 100 / len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some emails have NaNs for their subjects\n",
    "def handle_missing_data(data):\n",
    "    data = data.fillna('')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frac_upper(string):\n",
    "    \"\"\"Computes the fraction of alphabetical characters\n",
    "    in STRING that are uppercase. If no alphabetical\n",
    "    characters, returns 0.\"\"\"\n",
    "    num_upper = len(re.findall(r'[A-Z]', string))\n",
    "    num_letters = len(re.findall(r'[a-zA-Z]', string))\n",
    "    if num_letters == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return num_upper / num_letters\n",
    "    \n",
    "def number_of(regex):\n",
    "    \"\"\"Returns a lambda that when applied to a string\n",
    "    will count the number of occurences of REGEX in the\n",
    "    string (for use in making new features below).\"\"\"\n",
    "    return lambda string: len(re.findall(regex, string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_features(data):\n",
    "    # Combine subject and email columns\n",
    "    data['combined'] = data['subject'] + ' ' + data['email']\n",
    "\n",
    "    # Make everything in 'combined' lowercase and remove punctuation\n",
    "    data['no_punc'] = (\n",
    "        data['combined']\n",
    "        .str.lower()\n",
    "        .str.replace(pat=r'[^\\w\\s]', repl=' ')\n",
    "    )\n",
    "    \n",
    "    # Count number of characters, words, new line characters,\n",
    "    # etc. Take logs of these. Also compute fraction of\n",
    "    # uppercase letters in email\n",
    "    data['log_chars'] = np.log1p(data['combined'].apply(len))\n",
    "    data['log_words'] = np.log1p(data['no_punc'].apply(lambda string: len(string.split())))\n",
    "    data['log_new_lines'] = np.log1p(data['combined'].apply(number_of(r'[\\n]')))\n",
    "    data['log_angle_brackets'] = np.log1p(data['combined'].apply(number_of(r'[<>]')))\n",
    "    data['log_exclamations'] = np.log1p(data['combined'].apply(number_of(r'[!]')))\n",
    "    data['log_punctuation'] = np.log1p(data['combined'].apply(number_of(r'[\\n$%<>!?]')))\n",
    "    data['frac_upper'] = data['combined'].apply(frac_upper)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following function runs only on 'train' so as to\n",
    "# guarantee that, when we run our data through the pipeline,\n",
    "# the same words are used for both 'train' and 'test'.\n",
    "def spam_ham_words(min_emails):\n",
    "    # Combine subject and email columns\n",
    "    train['combined'] = train['subject'] + ' ' + train['email']\n",
    "    \n",
    "    # Make everything in 'combined' lowercase and remove punctuation\n",
    "    train['no_punc'] = (\n",
    "        train['combined']\n",
    "        .str.lower()\n",
    "        .str.replace(pat=r'[^\\w\\s]', repl=' ')\n",
    "    )\n",
    "    \n",
    "    # Put email text into \"tidy format\", i.e., each word of each\n",
    "    # email gets put into its own row, indexed by id of email\n",
    "    tidy_format = (\n",
    "        train['no_punc']\n",
    "        .str.split(expand=True)\n",
    "        .stack()\n",
    "        .reset_index(level=1)\n",
    "        .rename(columns={'level_1': 'num', 0: 'word'})\n",
    "        # The following lines drop repeated words in same email\n",
    "        # Not sure if should keep these\n",
    "        #.drop('num', axis=1)\n",
    "        #.reset_index()\n",
    "        #.drop_duplicates()\n",
    "        #.set_index('index')\n",
    "    )\n",
    "    \n",
    "    # Find which words are most indicative of a spam email\n",
    "    # versus a ham email. Limit to words appearing in at\n",
    "    # least 'min_emails' emails\n",
    "    words = (\n",
    "        tidy_format\n",
    "        .groupby('word')\n",
    "        .filter(lambda x: x.index.nunique() >= min_emails)\n",
    "        .merge(train[['spam']], how=\"left\", left_index=True, right_index=True)\n",
    "        .groupby('word')[['spam']]\n",
    "        .mean()\n",
    "        .sort_values('spam', ascending=False)\n",
    "    )\n",
    "    \n",
    "    return words\n",
    "\n",
    "def words_in_texts(words, texts):\n",
    "    \"\"\"Returns a dataframe the (i, j)^th entry of which is 1 \n",
    "    if the i^th element of TEXTS contains the j^th element of\n",
    "    WORDS as a substring and is 0 otherwise.\"\"\"\n",
    "    indicator_array = np.array([texts.str.contains(word).astype(int) for word in words]).T\n",
    "    df = pd.DataFrame(indicator_array, columns=words)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_words_cols(data, words):\n",
    "    \"\"\"For each word in WORDS, appends a binary feature \n",
    "    indicating whether that word appears in a given email.\"\"\"\n",
    "    # Must reset index on 'data' for use in concat\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    words_in_texts_df = words_in_texts(words, data['no_punc'])\n",
    "    data = pd.concat([data, words_in_texts_df], axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneeded columns\n",
    "def drop_cols(data, cols):\n",
    "    data = data.drop(cols, axis=1)\n",
    "    return data\n",
    "\n",
    "cols_to_drop = ['id', 'subject', 'email', 'combined', 'no_punc']\n",
    "#cols_to_drop = ['id', 'subject', 'email', 'combined', 'no_punc', 'log_angle_brackets', 'log_exclamations']\n",
    "\n",
    "# The graphs for 'log_angle_brackets' and 'log_exclamations'\n",
    "# are strange. Not clear whether we should include these\n",
    "# features. We'll try running the model with them and\n",
    "# try it again without them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process_pipeline(data):\n",
    "    data = (\n",
    "        data\n",
    "        .pipe(handle_missing_data)\n",
    "        .pipe(make_new_features)\n",
    "        .pipe(append_words_cols, words)\n",
    "        .pipe(drop_cols, cols_to_drop)\n",
    "    )\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider using LogisticRegressionCV\n",
    "#### Also, hyperparams to tweak: 'min_emails', 'num_spam', and 'num_ham' in 'spam_ham_words', as well as classification threshold in LogisticRegression model object. Also consider dropping the 'log_angle_brackets' and 'log_exclamations' cols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/efscerbo/anaconda3/envs/data100/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/efscerbo/anaconda3/envs/data100/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter optimization\n",
    "#\n",
    "# To do this \"right\", probably want to use KFold and\n",
    "# split the training set. Also, will probably want to\n",
    "# optimize recall rather than accuracy; see below\n",
    "\n",
    "import itertools\n",
    "\n",
    "min_emails_range = range(600, 1201, 100)\n",
    "num_spam_range = range(30, 101, 15)\n",
    "num_ham_range = range(30, 101, 15)\n",
    "\n",
    "training_scores = {}\n",
    "test_scores = {}\n",
    "\n",
    "# Use nested 'for' loops here b/c computing 'words' is\n",
    "# the most expensive part. No sense recomputing 'words'\n",
    "# multiple times w the same value of 'min_emails'\n",
    "for min_emails in min_emails_range:\n",
    "    words_df = spam_ham_words(min_emails)\n",
    "    for num_spam, num_ham in itertools.product(num_spam_range, num_ham_range):\n",
    "        spam_words = words_df.index[:num_spam].tolist()\n",
    "        ham_words = words_df.index[-num_ham:].tolist()\n",
    "        words = spam_words + ham_words\n",
    "        \n",
    "        processed_train = data_process_pipeline(train.copy().rename(columns={'spam': 'Spam'}))\n",
    "        processed_test = data_process_pipeline(test.copy().rename(columns={'spam': 'Spam'}))\n",
    "        \n",
    "        X_train = processed_train.drop('Spam', axis=1)\n",
    "        y_train = processed_train['Spam']\n",
    "        X_test = processed_test.drop('Spam', axis=1)\n",
    "        y_test = processed_test['Spam']\n",
    "        \n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        scores = {}\n",
    "        \n",
    "        for C in np.linspace(0, 1, 100):\n",
    "            y_pred = 1*(model.predict_proba(X_train)[:, 1] > C)\n",
    "            # May want to track a different metric here instead of\n",
    "            # accuracy, maybe precision, recall or f1. Look into this\n",
    "            score = sum(y_pred == y_train) / len(y_train)\n",
    "            scores[C] = score\n",
    "        \n",
    "        C = max(scores, key=scores.get)\n",
    "        \n",
    "        y_train_pred = 1*(model.predict_proba(X_train)[:, 1] > C)\n",
    "        training_accuracy = sum(y_train_pred == y_train) / len(y_train)\n",
    "        \n",
    "        y_test_pred = 1*(model.predict_proba(X_test)[:, 1] > C)\n",
    "        test_accuracy = sum(y_test_pred == y_test) / len(y_test)\n",
    "        \n",
    "        quadruple = (min_emails, num_spam, num_ham, C)\n",
    "        training_scores[quadruple] = training_accuracy\n",
    "        test_scores[quadruple] = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_emails, num_spam, num_ham, C = max(test_scores, key=test_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 90, 90, 0.45454545454545459)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(training_scores, key=training_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/efscerbo/anaconda3/envs/data100/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/efscerbo/anaconda3/envs/data100/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "words_df = spam_ham_words(min_emails)\n",
    "spam_words = words_df.index[:num_spam].tolist()\n",
    "ham_words = words_df.index[-num_ham:].tolist()\n",
    "words = spam_words + ham_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataframes before modeling. Rename 'spam' as\n",
    "# 'Spam' bc one of the words found by 'spam_ham_words'\n",
    "# is 'spam'\n",
    "processed_train = data_process_pipeline(train.copy().rename(columns={'spam': 'Spam'}))\n",
    "processed_test = data_process_pipeline(test.copy().rename(columns={'spam': 'Spam'}))\n",
    "\n",
    "X_train = processed_train.drop('Spam', axis=1)\n",
    "y_train = processed_train['Spam']\n",
    "X_test = processed_test.drop('Spam', axis=1)\n",
    "y_test = processed_test['Spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9828297617463064\n",
      "Test Accuracy:  0.9760479041916168\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = 1*(model.predict_proba(X_train)[:, 1] > C)\n",
    "training_accuracy = sum(y_train_pred == y_train) / len(y_train)\n",
    "        \n",
    "y_test_pred = 1*(model.predict_proba(X_test)[:, 1] > C)\n",
    "test_accuracy = sum(y_test_pred == y_test) / len(y_test)\n",
    "\n",
    "#training_accuracy = model.score(X_train, y_train)\n",
    "#test_accuracy = model.score(X_test, y_test)\n",
    "print('Training Accuracy: ', training_accuracy)\n",
    "print('Test Accuracy: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a19c35e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98       601\n",
      "          1       0.96      0.94      0.95       234\n",
      "\n",
      "avg / total       0.97      0.97      0.97       835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict_proba(X_train)[:, 1]\n",
    "prec, recall, _ = precision_recall_curve(y_train, y_predict)\n",
    "plt.plot(recall, prec)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "evaluation = pd.read_csv('data/eval.csv')\n",
    "evaluation_predictions = model.predict(data_process_pipeline(evaluation.copy()))\n",
    "\n",
    "# Construct and save the submission:\n",
    "submission_df = pd.DataFrame({\n",
    "    \"Id\": evaluation['id'], \n",
    "    \"Class\": evaluation_predictions,\n",
    "}, columns=['Id', 'Class'])\n",
    "timestamp = datetime.isoformat(datetime.now()).split(\".\")[0]\n",
    "submission_df.to_csv(\"submission_{}.csv\".format(timestamp), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
